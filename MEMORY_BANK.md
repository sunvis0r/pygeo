# Memory Bank - PyGeo Project

## Project Overview
**Project Name:** PyGeo - Geological Data Visualization System  
**Purpose:** Visualization and analysis of well data for geological exploration  
**Technology Stack:** Python, Streamlit, Plotly, NumPy, Pandas, LASio  
**Target Users:** Geologists, petroleum engineers, data analysts

---

## Project Structure

```
pygeo/
â”œâ”€â”€ app.py                          # Main Streamlit application
â”œâ”€â”€ README.md                       # Project documentation
â”œâ”€â”€ README_DOCKER.md                # Docker deployment guide
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ Dockerfile                      # Docker image definition
â”œâ”€â”€ docker-compose.yml              # Multi-container orchestration
â”œâ”€â”€ .env                            # Environment variables (not in git)
â”œâ”€â”€ .env.example                    # Environment variables template
â”œâ”€â”€ .gitignore                      # Git ignore rules
â”œâ”€â”€ backend/                        # Backend modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ database.py                # PostgreSQL database manager
â”‚   â””â”€â”€ init_db.sql                # Database initialization script
â”œâ”€â”€ frontend/                       # Frontend modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ modules/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ data_loader.py         # Data loading utilities
â”‚       â”œâ”€â”€ preprocess.py          # Data preprocessing functions
â”‚       â””â”€â”€ visualizer.py          # Visualization functions
â””â”€â”€ src_data/                      # Source data directory
    â”œâ”€â”€ WELL_*.las                 # LAS files (67 wells)
    â”œâ”€â”€ dot_dtv/
    â”‚   â”œâ”€â”€ H                      # Formation thickness data
    â”‚   â””â”€â”€ EFF_H                  # Effective thickness data
    â””â”€â”€ INKL/
        â””â”€â”€ Ñ‚Ñ€Ð°ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¸             # Well trajectories file
```

---

## Core Modules

### 1. [`app.py`](app.py:1) - Main Application
**Purpose:** Streamlit web application entry point

**Key Features:**
- Multi-mode visualization interface
- Session state management
- Data loading orchestration
- Interactive controls and filters

**View Modes:**
1. **ÐšÐ°Ñ€Ñ‚Ð° (Map)** - 2D well location map with collector ratio
2. **3D Ñ‚Ñ€Ð°ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¸ (3D Trajectories)** - 3D well path visualization
3. **3D Ð¿Ð»Ð°ÑÑ‚Ñ‹ ÐºÐ¾Ð»Ð»ÐµÐºÑ‚Ð¾Ñ€Ð¾Ð² (3D Reservoir Layers)** - 3D reservoir visualization with well logs
4. **2D Ð¿Ñ€Ð¾ÐµÐºÑ†Ð¸Ñ ÑÐºÐ²Ð°Ð¶Ð¸Ð½Ñ‹ (2D Well Projection)** - 2D well cross-section with layers
5. **Ð Ð°Ð·Ñ€ÐµÐ·Ñ‹ (Cross-sections)** - Geophysical well logs
6. **ÐÐ½Ð°Ð»Ð¸Ð· (Analysis)** - Statistical analysis and data export

**Session State Variables:**
- `data_loaded`: Boolean flag for data loading status
- `trajectories`: Dictionary of well trajectories
- `well_data`: Combined DataFrame with H and EFF_H data
- `las_data`: Dictionary of LAS file data

**Key Functions:**
- Data loading button handler (lines 56-74)
- View mode switching (lines 42-46)
- Filter controls (lines 80-89)

---

### 2. [`frontend/modules/data_loader.py`](frontend/modules/data_loader.py:1) - Data Loading
**Purpose:** Load and parse various geological data formats

**Key Functions:**

#### [`load_welltrajectories(filepath)`](frontend/modules/data_loader.py:12)
- **Input:** Path to trajectory file
- **Output:** Dict[well_name, np.ndarray[X, Y, Z, MD]]
- **Format:** Parses custom trajectory format with `welltrack 'WELL_XXX'` headers
- **Data Structure:** Each trajectory is [X, Y, Z, MD] where MD = Measured Depth

#### [`load_h_data(filepath)`](frontend/modules/data_loader.py:63)
- **Input:** Path to H (thickness) data file
- **Output:** DataFrame with columns [X, Y, Z, Well, H]
- **Format:** Space-separated values with # comments

#### [`load_eff_h_data(filepath)`](frontend/modules/data_loader.py:80)
- **Input:** Path to EFF_H (effective thickness) data file
- **Output:** DataFrame with columns [X, Y, Z, Well, EFF_H]
- **Purpose:** Loads effective thickness (collector zones only)

#### [`load_las_file(filepath)`](frontend/modules/data_loader.py:97)
- **Input:** Path to LAS file
- **Output:** Dict with keys: `well_name`, `depth`, `curve`, `null_value`
- **Library:** Uses `lasio` library
- **Curve Name:** Looks for 'ÐšÑ€Ð¸Ð²Ð°ÑÐ“Ð˜Ð¡1' or uses first curve
- **Null Value:** -999.25 (standard missing data marker)

#### [`load_all_las_files(folder_path)`](frontend/modules/data_loader.py:125)
- **Input:** Folder path containing LAS files
- **Output:** Dict[well_name, las_data]
- **Supported Extensions:** .las, .txt

#### [`combine_all_data(h_path, eff_h_path)`](frontend/modules/data_loader.py:151)
- **Input:** Paths to H and EFF_H files
- **Output:** Merged DataFrame with calculated collector ratio
- **Calculated Field:** `Ð”Ð¾Ð»Ñ_ÐºÐ¾Ð»Ð»ÐµÐºÑ‚Ð¾Ñ€Ð° = EFF_H / H` (collector ratio)
- **Data Cleaning:** Removes NaN values, handles division by zero

---

### 3. [`frontend/modules/preprocess.py`](frontend/modules/preprocess.py:1) - Data Preprocessing
**Purpose:** Data cleaning, interpolation, and preparation for ML

**Key Functions:**

#### [`clean_las_data(las_data)`](frontend/modules/preprocess.py:10)
- **Purpose:** Remove null values (-999.25) from LAS data
- **Returns:** Cleaned dictionary with valid data only

#### [`interpolate_trajectory(trajectory, step=1.0)`](frontend/modules/preprocess.py:34)
- **Purpose:** Interpolate well trajectory with uniform step
- **Input:** Trajectory array [X, Y, Z, MD]
- **Output:** Interpolated trajectory with specified MD step
- **Method:** Linear interpolation using `np.interp`

#### [`create_grid_from_points(df, grid_size=100)`](frontend/modules/preprocess.py:64)
- **Purpose:** Create regular grid for spatial interpolation
- **Returns:** X_grid, Y_grid meshgrid arrays
- **Padding:** Adds 10% padding around data bounds

#### [`prepare_ml_data(df, las_dict)`](frontend/modules/preprocess.py:99)
- **Purpose:** Prepare data structure for ML model integration
- **Output:** Dictionary with coordinates, labels, well names, and LAS data
- **Use Case:** Ready for ML model from 1st year team

#### [`filter_by_depth(las_data, min_depth, max_depth)`](frontend/modules/preprocess.py:129)
- **Purpose:** Filter LAS data by depth range
- **Returns:** Filtered LAS data dictionary

---

### 4. [`frontend/modules/visualizer.py`](frontend/modules/visualizer.py:1) - Visualization
**Purpose:** Create interactive Plotly visualizations

**Key Functions:**

#### [`create_2d_map(df, show_well_names=True)`](frontend/modules/visualizer.py:12)
- **Purpose:** 2D map view of well locations
- **Color Scale:** Viridis colormap based on collector ratio
- **Features:** Well names, hover info, equal aspect ratio
- **Returns:** Plotly Figure

#### [`create_3d_trajectories(trajectories)`](frontend/modules/visualizer.py:61)
- **Purpose:** 3D visualization of well paths
- **Features:** 
  - Colored lines for each well
  - Start/end markers
  - Hover information with depth
- **Aspect Ratio:** x=1, y=1, z=0.7

#### [`create_las_cross_section(las_data, well_name)`](frontend/modules/visualizer.py:131)
- **Purpose:** Display well log cross-section
- **Color Coding:**
  - Yellow: Collector (value = 1)
  - Gray: Non-collector (value = 0)
  - Light blue: Other values
- **Y-axis:** Reversed (depth increases downward)

#### [`create_prediction_heatmap(X_grid, Y_grid, Z_pred)`](frontend/modules/visualizer.py:200)
- **Purpose:** Display ML prediction results as heatmap
- **Color Scale:** RdBu_r (red-blue reversed)
- **Use Case:** Placeholder for ML model integration

#### [`create_well_comparison(df)`](frontend/modules/visualizer.py:230)
- **Purpose:** Comparative bar chart of well characteristics
- **Displays:**
  - H (formation thickness) - light blue bars
  - EFF_H (effective thickness) - orange bars
  - Collector ratio - red line on secondary axis

#### [`create_3d_reservoir_layers(well_data, trajectories, las_data, ...)`](frontend/modules/visualizer.py:286)
- **Purpose:** 3D visualization combining well trajectories with collector layers
- **Approach:** Uses trajectory-based rendering (like create_3d_trajectories) with layer visualization (like create_2d_well_projection)
- **Features:**
  - Well trajectories with colored lines
  - Collector/non-collector layers rendered along trajectories
  - Accurate MD to X,Y,Z mapping using trajectory interpolation
  - Start/end markers for each well
  - Legend for layer types
- **Layer Rendering:**
  - Green thick lines (width=10): Collector intervals (value=1)
  - Gray lines (width=8): Non-collector intervals (value=0)
  - Layers follow actual well trajectory in 3D space
- **MD Mapping:**
  - Uses np.interp to map LAS MD values to trajectory X,Y,Z coordinates
  - Handles both vertical and deviated wells correctly
  - Validates MD range compatibility between LAS and trajectory data
- **Aspect Ratio:** x=1, y=1, z=0.7 (same as 3D trajectories view)

#### [`create_2d_well_projection(well_data, las_data, selected_well)`](frontend/modules/visualizer.py:556)
- **Purpose:** 2D vertical cross-section of single well
- **Features:**
  - Layer visualization (green=collector, gray=non-collector)
  - Red wiggle trace for log curve
  - Black vertical line for wellbore
  - Top/bottom markers (blue/red triangles)
  - Information annotations
- **Scaling:** Normalized depth to well thickness range

---

## Data Formats

### 1. Well Trajectories File (`src_data/INKL/Ñ‚Ñ€Ð°ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¸`)
```
welltrack 'WELL_034'
7131.91 75939.70 71.62 0.00
7131.88 75939.60 61.62 10.00
...
```
- **Format:** Custom text format
- **Fields:** X, Y, Z, MD (Measured Depth)
- **Encoding:** UTF-8 (supports Cyrillic)

### 2. H Data File (`src_data/dot_dtv/H`)
```
# Comment line
X Y Z Well H
6681.46 74209.62 1086.29 WELL_067 8.62
```
- **Format:** Space-separated values
- **Fields:** X, Y, Z (coordinates), Well (name), H (thickness in meters)

### 3. EFF_H Data File (`src_data/dot_dtv/EFF_H`)
```
# Comment line
X Y Z Well EFF_H
6681.46 74209.62 1086.29 WELL_067 5.23
```
- **Format:** Space-separated values
- **Fields:** X, Y, Z (coordinates), Well (name), EFF_H (effective thickness)

### 4. LAS Files (`src_data/WELL_*.las`)
- **Format:** Standard LAS 2.0 format
- **Key Curve:** ÐšÑ€Ð¸Ð²Ð°ÑÐ“Ð˜Ð¡1 (Geophysical log curve)
- **Values:**
  - 1 = Effective collector
  - 0 = Non-collector or ineffective collector
  - -999.25 = Missing data
- **Index:** DEPT (depth)

---

## Key Concepts

### Geological Terms
- **H (ÐœÐ¾Ñ‰Ð½Ð¾ÑÑ‚ÑŒ Ð¿Ð»Ð°ÑÑ‚Ð°):** Total formation thickness in meters
- **EFF_H (Ð­Ñ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð°Ñ Ð¼Ð¾Ñ‰Ð½Ð¾ÑÑ‚ÑŒ):** Effective thickness (collector zones only)
- **Ð”Ð¾Ð»Ñ ÐºÐ¾Ð»Ð»ÐµÐºÑ‚Ð¾Ñ€Ð° (Collector Ratio):** EFF_H / H (percentage of formation that is collector)
- **ÐšÐ¾Ð»Ð»ÐµÐºÑ‚Ð¾Ñ€ (Collector):** Reservoir rock with good porosity/permeability
- **ÐÐµÐºÐ¾Ð»Ð»ÐµÐºÑ‚Ð¾Ñ€ (Non-collector):** Rock with poor reservoir properties
- **ÐšÑ€Ð¾Ð²Ð»Ñ (Top):** Top boundary of formation
- **ÐŸÐ¾Ð´Ð¾ÑˆÐ²Ð° (Bottom):** Bottom boundary of formation
- **Ð“Ð˜Ð¡ (Geophysical Investigation of Wells):** Well logging data

### Coordinate System
- **X, Y:** Horizontal coordinates (meters)
- **Z:** Vertical depth (meters, positive downward)
- **MD:** Measured Depth along wellbore (meters)

---

## Dependencies (requirements.txt)
```
streamlit==1.31.0       # Web application framework
plotly==5.18.0          # Interactive plotting
pandas==2.2.0           # Data manipulation
numpy==1.26.3           # Numerical computing
lasio==0.31             # LAS file reading
scipy==1.12.0           # Scientific computing (interpolation)
psycopg2-binary==2.9.9  # PostgreSQL adapter
python-dotenv==1.0.0    # Environment variables
```

---

## Current State & Known Issues

### Implemented Features âœ…
- Multi-view visualization system
- LAS file loading and parsing
- 3D trajectory visualization
- 3D reservoir layer visualization along trajectories
- Accurate MD to Z coordinate mapping
- Well log display with color coding
- Statistical analysis tools
- Data export functionality
- Interactive filtering

### Placeholders / TODO ðŸš§
- ML model integration (line 169-193 in app.py)
- Backend module implementation
- Advanced interpolation methods (Kriging, IDW, RBF)
- Performance optimization for large datasets

### Technical Notes
- **Browser Compatibility:** Requires modern browser with WebGL support
- **Data Size:** 67 wells with full trajectory and log data
- **Performance:** Grid resolution set to 40x40 for balance of quality/speed
- **Encoding:** UTF-8 required for Cyrillic characters in data files

---

## Usage Patterns

### Typical Workflow
1. Click "Ð—Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚ÑŒ Ð²ÑÐµ Ð´Ð°Ð½Ð½Ñ‹Ðµ" (Load all data) in sidebar
2. Wait for data loading confirmation
3. Select view mode from radio buttons
4. Adjust filters and settings as needed
5. Interact with visualizations (zoom, rotate, hover)
6. Export data if needed (Analysis tab)

### View Mode Selection Guide
- **ÐšÐ°Ñ€Ñ‚Ð°:** Quick overview of well locations and collector distribution
- **3D Ñ‚Ñ€Ð°ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¸:** Understand well paths and drilling patterns
- **3D Ð¿Ð»Ð°ÑÑ‚Ñ‹ ÐºÐ¾Ð»Ð»ÐµÐºÑ‚Ð¾Ñ€Ð¾Ð²:** Comprehensive 3D reservoir visualization
- **2D Ð¿Ñ€Ð¾ÐµÐºÑ†Ð¸Ñ ÑÐºÐ²Ð°Ð¶Ð¸Ð½Ñ‹:** Detailed single-well analysis
- **Ð Ð°Ð·Ñ€ÐµÐ·Ñ‹:** Examine raw geophysical log data
- **ÐÐ½Ð°Ð»Ð¸Ð·:** Statistical analysis and data export

---

## Integration Points

### ML Model Integration
- **Data Preparation:** Use [`prepare_ml_data()`](frontend/modules/preprocess.py:99)
- **Prediction Display:** Use [`create_prediction_heatmap()`](frontend/modules/visualizer.py:200)
- **Input Features:** X, Y, Z coordinates + LAS curve data
- **Target Variable:** Collector ratio (0-1)
- **Location:** Lines 169-193 in [`app.py`](app.py:169)

### Future Enhancements
- Real-time data updates
- Advanced geostatistical methods
- 4D visualization (time dimension)
- Multi-user collaboration features
- Cloud deployment

---

## File Naming Conventions
- Wells: `WELL_XXX` where XXX is 3-digit number (001-076)
- LAS files: `WELL_XXX.las`
- Data files: Descriptive names in Russian (H, EFF_H, Ñ‚Ñ€Ð°ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¸)

---

## Color Schemes

### Collector Visualization
- **Green:** Collector zones (value = 1)
- **Gray:** Non-collector zones (value = 0)
- **Yellow/Orange:** High collector ratio surfaces
- **Red:** Log curves
- **Black:** Wellbore traces

### Map Visualization
- **Viridis:** Collector ratio gradient (purple to yellow)
- **Qualitative.Plotly:** Well trajectory colors

---

## Performance Considerations
- Grid resolution: 40x40 (adjustable in code)
- Interpolation method: Cubic (balance of smoothness/speed)
- LAS data filtering: Remove null values before processing
- Session state: Prevents redundant data loading

---

## Error Handling
- Missing files: Graceful degradation with warnings
- Invalid data: NaN filtering and error messages
- Empty wells: Skip in visualizations
- Division by zero: Protected in collector ratio calculation

---

## Contact & Support
- **Team:** 2nd year course team
- **Event:** Hackathon: Software Development Technologies
- **Repository:** Git-based version control (main, dev, feature/* branches)

---

## Recent Changes (2025-12-16)

### MD to Z Mapping Fix
- **Issue:** Incorrect mapping of Measured Depth (MD) to Z coordinates in 3D visualization
- **Root Cause:** Linear approximation assumed MD = Z, which is incorrect for deviated wells
- **Solution:**
  - Implemented proper MD interpolation using trajectory data
  - Added validation of MD range compatibility
  - Added fallback handling for vertical wells
  - Files modified: [`frontend/modules/visualizer.py`](frontend/modules/visualizer.py:286)

### 3D Reservoir Layers Redesign
- **Change:** Complete rewrite of [`create_3d_reservoir_layers()`](frontend/modules/visualizer.py:286)
- **Old Approach:** Surface interpolation with griddata (top/bottom surfaces)
- **New Approach:** Trajectory-based layer rendering
  - Renders collector/non-collector segments along actual well trajectories
  - Uses same visualization style as [`create_3d_trajectories()`](frontend/modules/visualizer.py:61)
  - Applies layer logic from [`create_2d_well_projection()`](frontend/modules/visualizer.py:551)
- **Benefits:**
  - More accurate representation of geology along wellbore
  - Correct handling of deviated wells
  - Better visual clarity
  - Consistent with other 3D views

### Key Technical Details
- **MD (Measured Depth):** Length along wellbore from surface
- **Z Coordinate:** Vertical depth (can differ from MD in deviated wells)
- **Mapping Formula:** `Z = np.interp(MD_las, MD_trajectory, Z_trajectory)`
- **Layer Segments:** Grouped by consecutive collector/non-collector values

---

## Docker Infrastructure (Added 2025-12-16)

### Overview
Complete containerization with PostgreSQL database integration for production deployment.

### Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Streamlit App (Port 8501)       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Frontend (Streamlit UI)          â”‚  â”‚
â”‚  â”‚  - Visualization (Plotly)         â”‚  â”‚
â”‚  â”‚  - Interactive controls           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Backend (Python)                 â”‚  â”‚
â”‚  â”‚  - Data Loader (files)            â”‚  â”‚
â”‚  â”‚  - Database Manager (PostgreSQL)  â”‚  â”‚
â”‚  â”‚  - Preprocessor                   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      PostgreSQL Database (Port 5432)    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Tables:                          â”‚  â”‚
â”‚  â”‚  - wells (ÑÐºÐ²Ð°Ð¶Ð¸Ð½Ñ‹)               â”‚  â”‚
â”‚  â”‚  - trajectories (Ñ‚Ñ€Ð°ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¸)      â”‚  â”‚
â”‚  â”‚  - las_data (ÐºÐ°Ñ€Ð¾Ñ‚Ð°Ð¶)             â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Components

#### 1. [`Dockerfile`](Dockerfile:1)
- **Base Image:** python:3.11-slim
- **System Dependencies:** gcc, postgresql-client, build-essential
- **Working Directory:** /app
- **Exposed Port:** 8501
- **Healthcheck:** HTTP check on /healthz endpoint
- **Entry Point:** streamlit run app.py

#### 2. [`docker-compose.yml`](docker-compose.yml:1)
**Services:**
- **postgres:**
  - Image: postgres:15-alpine
  - Database: pygeo_db
  - User: pygeo_user
  - Port: 5432
  - Volume: postgres_data (persistent storage)
  - Healthcheck: pg_isready
  
- **app:**
  - Build: Current directory
  - Depends on: postgres
  - Port: 8501
  - Volumes:
    - src_data (read-only) - source data files
    - data (read-write) - application data
  - Environment: DATABASE_URL, DATA_SOURCE
  - Restart: unless-stopped

#### 3. [`backend/database.py`](backend/database.py:1)
**Class:** DatabaseManager

**Connection Management:**
- Uses psycopg2.pool.SimpleConnectionPool
- Min connections: 1
- Max connections: 10
- Automatic connection lifecycle management

**Key Methods:**
- `save_well(name, x, y, z, h, eff_h, collector_ratio)` - Save well data
- `get_all_wells()` - Retrieve all wells
- `save_trajectory(well_id, x, y, z, md)` - Save trajectory point
- `get_all_trajectories()` - Retrieve all trajectories
- `save_las_data(well_id, depth, curve_value)` - Save LAS data
- `get_all_las_data()` - Retrieve all LAS data
- `load_data_from_files_to_db()` - Bulk load from src_data files

**Error Handling:**
- Try-except blocks for all database operations
- Automatic connection return to pool
- Graceful degradation on errors

#### 4. [`backend/init_db.sql`](backend/init_db.sql:1)
**Database Schema:**

**Table: wells**
- id (SERIAL PRIMARY KEY)
- name (VARCHAR(50) UNIQUE NOT NULL)
- x, y, z (DOUBLE PRECISION)
- h, eff_h (DOUBLE PRECISION)
- collector_ratio (DOUBLE PRECISION)
- created_at, updated_at (TIMESTAMP)

**Table: trajectories**
- id (SERIAL PRIMARY KEY)
- well_id (INTEGER REFERENCES wells)
- x, y, z, md (DOUBLE PRECISION)
- created_at (TIMESTAMP)
- Index on well_id for fast lookups

**Table: las_data**
- id (SERIAL PRIMARY KEY)
- well_id (INTEGER REFERENCES wells)
- depth (DOUBLE PRECISION)
- curve_value (DOUBLE PRECISION)
- created_at (TIMESTAMP)
- Index on well_id for fast lookups

**Triggers:**
- update_wells_updated_at - Auto-update timestamp on wells table

### Environment Variables

**Required (.env file):**
```bash
POSTGRES_DB=pygeo_db
POSTGRES_USER=pygeo_user
POSTGRES_PASSWORD=your_secure_password
DATABASE_URL=postgresql://pygeo_user:your_secure_password@postgres:5432/pygeo_db
DATA_SOURCE=database  # or 'files'
```

### Data Source Modes

**1. Files Mode (DATA_SOURCE=files)**
- Loads data from src_data/ directory
- Uses existing data_loader.py functions
- No database required
- Default behavior

**2. Database Mode (DATA_SOURCE=database)**
- Loads data from PostgreSQL
- Uses DatabaseManager class
- Persistent storage
- Multi-user support

### Deployment Commands

**Start services:**
```bash
docker-compose up -d
```

**View logs:**
```bash
docker-compose logs -f app
docker-compose logs -f postgres
```

**Stop services:**
```bash
docker-compose down
```

**Rebuild after changes:**
```bash
docker-compose up -d --build
```

**Database backup:**
```bash
docker exec pygeo_postgres pg_dump -U pygeo_user pygeo_db > backup.sql
```

**Database restore:**
```bash
docker exec -i pygeo_postgres psql -U pygeo_user pygeo_db < backup.sql
```

### Volumes

**postgres_data:**
- Purpose: Persistent PostgreSQL data
- Location: Docker managed volume
- Survives container restarts

**src_data:**
- Purpose: Source data files (LAS, trajectories, etc.)
- Mount: ./src_data:/app/src_data:ro (read-only)
- Prevents accidental modification

**data:**
- Purpose: Application runtime data
- Mount: ./data:/app/data
- Read-write access

### Network

**pygeo_network:**
- Type: Bridge network
- Purpose: Inter-container communication
- Services: app, postgres
- DNS: Automatic service name resolution

### Health Checks

**PostgreSQL:**
- Command: pg_isready -U pygeo_user
- Interval: 10s
- Timeout: 5s
- Retries: 5

**Application:**
- Command: curl -f http://localhost:8501/healthz
- Interval: 30s
- Timeout: 10s
- Retries: 3

### Security Considerations

**Production Checklist:**
- [ ] Change default passwords in .env
- [ ] Use secrets management (Docker secrets, Vault)
- [ ] Enable SSL/TLS for PostgreSQL
- [ ] Configure firewall rules
- [ ] Use reverse proxy (nginx) with HTTPS
- [ ] Implement authentication for Streamlit
- [ ] Regular security updates
- [ ] Database backups automation

### Performance Optimization

**Database:**
- Connection pooling (1-10 connections)
- Indexes on foreign keys
- Batch inserts for bulk operations

**Application:**
- Read-only mount for source data
- Efficient data loading strategies
- Session state caching

### Monitoring

**Logs:**
- Application: docker-compose logs app
- Database: docker-compose logs postgres
- Combined: docker-compose logs -f

**Metrics:**
- Container stats: docker stats
- Database connections: SELECT count(*) FROM pg_stat_activity;
- Disk usage: docker system df

### Troubleshooting

**Issue: Container won't start**
```bash
docker-compose logs app
docker-compose ps
```

**Issue: Database connection failed**
```bash
docker-compose exec postgres pg_isready -U pygeo_user
docker-compose restart postgres
```

**Issue: Port already in use**
- Change port in docker-compose.yml
- Or stop conflicting service

**Issue: Data not persisting**
- Check volume mounts
- Verify postgres_data volume exists: docker volume ls

### Future Enhancements

**Planned:**
- [ ] Redis cache layer
- [ ] Nginx reverse proxy
- [ ] SSL/TLS certificates
- [ ] Automated backups
- [ ] Monitoring dashboard (Grafana)
- [ ] CI/CD pipeline
- [ ] Kubernetes deployment
- [ ] Multi-stage Docker builds

---

---

## User Experience & Presentation

### User Flow Documentation
**Complete user journey** from application launch to data export:

1. **Application Launch**
   - Docker containers startup
   - PostgreSQL database initialization
   - Streamlit web server activation

2. **Data Loading Phase**
   - One-click "Ð—Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚ÑŒ Ð²ÑÐµ Ð´Ð°Ð½Ð½Ñ‹Ðµ" button
   - Automatic parsing of 70+ source files
   - Database population with validation
   - Progress indicators and success confirmation

3. **Visualization Modes** (7 available views):
   - **ÐšÐ°Ñ€Ñ‚Ð° (Map)**: 2D well location overview with collector ratio heatmap
   - **3D Ñ‚Ñ€Ð°ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¸ (3D Trajectories)**: Spatial well path visualization
   - **3D Ð¿Ð»Ð°ÑÑ‚Ñ‹ ÐºÐ¾Ð»Ð»ÐµÐºÑ‚Ð¾Ñ€Ð¾Ð² (3D Reservoir Layers)**: Geological layer rendering along trajectories
   - **2D Ð¿Ñ€Ð¾ÐµÐºÑ†Ð¸Ñ ÑÐºÐ²Ð°Ð¶Ð¸Ð½Ñ‹ (2D Well Projection)**: Single well vertical cross-section
   - **Ð Ð°Ð·Ñ€ÐµÐ·Ñ‹ (Cross-sections)**: Raw geophysical log data display
   - **ÐÐ½Ð°Ð»Ð¸Ð· (Analysis)**: Statistical analysis and data export tools
   - **âž• Ð”Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ ÑÐºÐ²Ð°Ð¶Ð¸Ð½Ñƒ**: Create new wells with ML predictions
   - **ðŸ¤– ML Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ (ML Predictions)**: Demo mode for AI predictions

4. **Well Creation with ML Integration**
   - Access "âž• Ð”Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ ÑÐºÐ²Ð°Ð¶Ð¸Ð½Ñƒ" mode
   - Input well coordinates and depth range
   - Enable "ðŸ¤– Ð¡Ð³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ ML Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ" checkbox
   - Configure ML parameters (depth step, confidence level)
   - Submit to create well with automatic ML analysis
   - View immediate results: collector ratio, prediction chart
   - Data automatically saved to database as LAS records

5. **Interactive Exploration**
   - Filter controls (well selection, coordinate ranges, depth filters)
   - Plotly-powered zoom, rotate, pan operations
   - Hover tooltips with detailed information
   - Color-coded geological interpretations

6. **ML Predictions Workflow**
   - **Primary Usage**: Integrated into well creation process
   - **Demo Mode**: "ðŸ¤– ML Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ" for testing AI capabilities
   - Configure prediction parameters (depth range, confidence thresholds)
   - Generate predictions for new well locations
   - Visualize predictions on interactive map and charts
   - Compare AI predictions with real geological data

7. **Data Export**
   - CSV export of filtered datasets including ML predictions
   - Chart image downloads
   - Statistical report generation

### Presentation Slides Structure
**12-slide presentation framework** for project defense:

#### Slide 1: Title
- Project name: "PyGeo - Ð“ÐµÐ¾Ð»Ð¾Ð³Ð¸Ñ‡ÐµÑÐºÐ°Ñ ÑÐ¸ÑÑ‚ÐµÐ¼Ð° Ð²Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ñ…"
- Subtitle: "Ð¥Ð°ÐºÐ°Ñ‚Ð¾Ð½ 'Ð¢ÐµÑ…Ð½Ð¾Ð»Ð¾Ð³Ð¸Ð¸ Ñ€Ð°Ð·Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ ÐŸÐž'"
- Team credits and date

#### Slide 2: Problem Statement
- Challenges in geological data analysis
- Need for integrated visualization tools
- Complexity of multi-format data handling

#### Slide 3: Project Goals
- Integrated geological data visualization
- Real-time 2D/3D analysis
- Interactive reservoir property analysis
- Export capabilities for reporting

#### Slide 4: Technical Architecture
- Streamlit UI + Plotly Charts + PostgreSQL Backend
- Docker containerization
- Python data processing pipeline

#### Slide 5: Database Schema
- Three-table structure: wells, trajectories, las_data
- Entity relationships and constraints
- Performance indexes and data types

#### Slide 6: Data Sources
- LAS files: geophysical logging data
- Trajectory files: spatial well coordinates
- Thickness files: H and EFF_H formation data

#### Slide 7: Demo - Data Loading
- One-click loading process
- File parsing and validation
- Database population statistics

#### Slide 8: Demo - Map View
- Interactive well location map
- Collector ratio color coding
- Filtering and search capabilities

#### Slide 9: Demo - 3D Visualization
- Well trajectory rendering
- Reservoir layer visualization
- Interactive 3D controls

#### Slide 10: Demo - Detailed Analysis
- Single well cross-sections
- Log curve displays
- Statistical parameter tables

#### Slide 11: Results & Metrics
- 70 wells processed successfully
- 6 visualization modes implemented
- Full Docker containerization
- Complete documentation

#### Slide 12: Conclusion & Future
- Development roadmap
- Industrial application potential
- Team acknowledgments

---

## Recent Updates (2025-12-16 to 2025-12-17)

### Database Enhancement (2025-12-16)
- **Issue:** Incomplete well data loading due to coordinate precision mismatches
- **Root Cause:** Inner join on coordinates with microsecond differences
- **Solution:** Changed to left join on well names only, allowing null values in H/EFF_H
- **Result:** All 70 wells loaded (67 with complete data, 3 with partial data)

### ML Predictions Framework (2025-12-17)
- **Added:** Complete ML predictor mock framework for future AI integration
- **Added:** ðŸ¤– ML Predictions visualization mode with interactive controls
- **Added:** AI-powered well prediction generation and mapping
- **Added:** Comparative analysis between real and predicted geological data
- **Added:** Statistical metrics and confidence scoring for predictions

### Comprehensive Documentation (2025-12-17)
- **Added:** Complete README.md with database schema, user flow, presentation slides
- **Added:** Detailed entity descriptions and relationships
- **Added:** Technical architecture documentation
- **Added:** User experience flow mapping
- **Added:** 12-slide presentation framework with visual guidelines
- **Updated:** ML predictions integration in user flow and presentation

### Memory Bank Updates
- **Enhanced:** User flow documentation with step-by-step journey
- **Added:** Presentation slides structure with content guidelines
- **Updated:** Project metrics and achievements
- **Added:** Future development roadmap

---

## Key Metrics & Achievements

### Data Processing
- **Wells Processed:** 70 total (67 complete, 3 partial)
- **LAS Files:** 70 successfully parsed
- **Trajectory Points:** 2,100+ spatial coordinates
- **Formation Data:** H and EFF_H thickness measurements

### Technical Implementation
- **Database Tables:** 3 normalized tables with proper relationships
- **Visualization Modes:** 7 interactive views implemented
- **ML Integration:** Complete AI predictor workflow integrated into well creation
- **Automated ML Pipeline:** Well creation â†’ AI analysis â†’ Database storage â†’ Visualization
- **Containerization:** Full Docker deployment ready
- **Code Quality:** Modular architecture with separation of concerns

### User Experience
- **Loading Time:** < 30 seconds for full dataset
- **Interactive Performance:** Real-time 3D rendering
- **Export Capabilities:** CSV and image downloads
- **ML Workflow:** One-click AI analysis for new wells
- **Browser Compatibility:** Modern browsers with WebGL support

---

*Last Updated: 2025-12-17*
*Version: 1.5 - Integrated ML Well Creation & Complete AI Workflow*